{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\r\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\r\n",
      "     |████████████████████████████████| 7.4 MB 5.6 MB/s            \r\n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.27 in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from transformers) (4.62.3)\r\n",
      "Requirement already satisfied: requests in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from transformers) (2.26.0)\r\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\r\n",
      "  Using cached tokenizers-0.13.3-cp38-cp38-macosx_12_0_arm64.whl (3.9 MB)\r\n",
      "Collecting safetensors>=0.3.1\r\n",
      "  Downloading safetensors-0.3.1-cp38-cp38-macosx_12_0_arm64.whl (401 kB)\r\n",
      "     |████████████████████████████████| 401 kB 6.0 MB/s            \r\n",
      "\u001B[?25hRequirement already satisfied: pyyaml>=5.1 in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from transformers) (1.22.3)\r\n",
      "Requirement already satisfied: filelock in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from transformers) (3.12.2)\r\n",
      "Collecting regex!=2019.12.17\r\n",
      "  Downloading regex-2023.6.3-cp38-cp38-macosx_11_0_arm64.whl (288 kB)\r\n",
      "     |████████████████████████████████| 288 kB 6.3 MB/s            \r\n",
      "\u001B[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from transformers) (0.16.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from transformers) (23.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from requests->transformers) (2.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from requests->transformers) (3.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bradlystadie/miniforge3/lib/python3.8/site-packages (from requests->transformers) (2023.5.7)\r\n",
      "Installing collected packages: tokenizers, safetensors, regex, transformers\r\n",
      "Successfully installed regex-2023.6.3 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "example_text = 'Renewable energy sources, such as solar, wind, and hydroelectric power, are gaining traction as viable alternatives to fossil fuels. These sources harness naturally available resources, reducing our reliance on finite and environmentally harmful energy sources. Solar energy, for instance, utilizes photovoltaic panels to convert sunlight into electricity. Wind energy harnesses the power of wind turbines to produce clean and sustainable electricity. Hydroelectric power, on the other hand, generates electricity by utilizing the force of flowing water. The widespread adoption of renewable energy technologies can mitigate climate change by reducing greenhouse gas emissions. Government initiatives and incentives are encouraging the transition towards renewable energy, offering tax credits and grants to individuals and businesses. Additionally, investment in research and development is driving innovation in this sector, leading to more efficient and cost-effective renewable energy solutions. As renewable energy infrastructures expand, job creation in the green energy sector is expected to rise, stimulating economic growth. Moreover, decentralized renewable energy systems can improve energy access for remote and underserved communities. The integration of renewable energy into the power grid is enhancing grid stability and resilience while providing consumers with affordable and sustainable electricity options.'\n",
    "\n",
    "example_texts = [example_text for _ in range(100)]\n",
    "\n",
    "with open('test_file.csv', 'w', newline='') as csv_output:\n",
    "        fieldnames = ['text']\n",
    "\n",
    "        # Create a CSV writer object\n",
    "        csv_writer = csv.DictWriter(csv_output, fieldnames=fieldnames)\n",
    "\n",
    "        # Write the header\n",
    "        csv_writer.writeheader()\n",
    "\n",
    "        for ex_txt in example_texts:\n",
    "\n",
    "            # Write the combined data for the current row\n",
    "            csv_writer.writerow({'text': ex_txt})\n",
    "\n",
    "\n",
    "csv_output.close()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_first_and_remaining_sentences(text, num_first):\n",
    "    sentences = text.split('. ')\n",
    "    first_three_sentences = '. '.join(sentences[:num_first]) + '.'\n",
    "    remaining_sentences = '. '.join(sentences[num_first:]) + '.'\n",
    "    return first_three_sentences, remaining_sentences\n",
    "\n",
    "\n",
    "# Open the input CSV file\n",
    "with open('test_file.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "    # Open the output CSV file for writing\n",
    "    with open('test_properly_formatted_data.csv', 'w', newline='') as csv_output:\n",
    "        fieldnames = ['input', 'target']\n",
    "\n",
    "        # Create a CSV writer object\n",
    "        csv_writer = csv.DictWriter(csv_output, fieldnames=fieldnames)\n",
    "\n",
    "        # Write the header\n",
    "        csv_writer.writeheader()\n",
    "\n",
    "        # Loop through the rows, combine the author and quote, and write to the new CSV file\n",
    "        for row in csv_reader:\n",
    "            ex_text = row['text']\n",
    "            first_k_sentences, remaining_sentences = get_first_and_remaining_sentences(ex_text, num_first=3)\n",
    "\n",
    "            # Write the combined data for the current row\n",
    "            csv_writer.writerow({'input': ex_text, 'target': remaining_sentences})\n",
    "\n",
    "    csv_output.close()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from custom_dataset import customData\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_id = 'daryl149/Llama-2-7b-hf'\n",
    "# Pull the tokenizer.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "dataset = customData(tokenizer=tokenizer, csv_name='test_properly_formatted_data.csv')\n",
    "#from datasets import load_dataset\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "#df = pd.read_csv('test_properly_formatted_data.csv')\n",
    "#dataset = Dataset.from_pandas(df)\n",
    "\n",
    "#load_dataset(\n",
    "#                \"csv\",\n",
    "#                data_files='/Users/bradlystadie/Documents/GitHub/three-cases/test_properly_formatted_data.csv',  # \"eval\": \"grammar_validation.csv\"},\n",
    "#                delimiter=\",\",\n",
    "#            )\n",
    "\n",
    "#data_files = {\"train\": \"test_properly_formatted_data.csv\", \"test\": \"test_properly_formatted_data.csv\"}\n",
    "#dataset = load_dataset(\"namespace/your_dataset_name\", data_files=data_files)\n",
    "\n",
    "# dataset = load_dataset(\"csv\", data_files=\"test_properly_formatted_data.csv\")\n",
    "\n",
    "\n",
    "# dataset = customData(tokenizer=tokenizer, csv_name='test_properly_formatted_data.csv')\n",
    "\n",
    "# dataset.save_to_disk(\"test_dataset.hf\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "# This is a library that can just pull datasets. They're expected to be in a standard format.\n",
    "data = load_dataset(\"Abirate/english_quotes\")\n",
    "\n",
    "# LLAMA weights.\n",
    "model_id = 'daryl149/Llama-2-7b-hf'\n",
    "# Pull the tokenizer.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Apply the tokenizer to each sample in the dataset.\n",
    "data = data.map(lambda samples: tokenizer(samples[\"quote\"]), batched=True)\n",
    "\n",
    "# data has train and split.\n",
    "one_data = data['train'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datasets\n",
    "from utils import Concatenator\n",
    "\n",
    "def get_preprocessed_samsum(dataset_config, tokenizer, split):\n",
    "    dataset = datasets.load_dataset(\"samsum\", split=split)\n",
    "\n",
    "\n",
    "\n",
    "    # this trick of defining a formatting and then calling prompt.format(key_1=string_1)\n",
    "    # is very useful if you have multiple keys that you need to\n",
    "    # compress into a single string.\n",
    "    # for example, in this case we want to take a dialogue and\n",
    "    # learn a model that produces a summary.\n",
    "    # We can define a prompt that expects to get the dialogue\n",
    "    # and the summary as input\n",
    "    # and then also adds the flavor text at the start and the eos token at the end.\n",
    "    prompt = (\n",
    "        f\"Summarize this dialog:\\n{{dialog}}\\n---\\nSummary:\\n{{summary}}{{eos_token}}\"\n",
    "    )\n",
    "\n",
    "    # this function actually applies the prompt to the given sample.\n",
    "    # You can then call this with a map function.\n",
    "    def apply_prompt_template(sample):\n",
    "        return {\n",
    "            \"text\": prompt.format(\n",
    "                dialog=sample[\"dialogue\"],\n",
    "                summary=sample[\"summary\"],\n",
    "                eos_token=tokenizer.eos_token,\n",
    "            )\n",
    "        }\n",
    "\n",
    "    dataset = dataset.map(apply_prompt_template, remove_columns=list(dataset.features))\n",
    "\n",
    "    # This tokenizes the data after putting it into the correct prompt format.\n",
    "    # The line at the end .map(Concatenator()) basically\n",
    "    # takes multiple strings with the EOS token at the end of each string.\n",
    "    # it then concats them together.\n",
    "    # this helps with training efficiency, since now each of your inputs\n",
    "    # to the model are guaranteed to have the same size.\n",
    "    dataset = dataset.map(\n",
    "        lambda sample: tokenizer(sample[\"text\"]),\n",
    "        batched=True,\n",
    "        remove_columns=list(dataset.features),\n",
    "    ).map(Concatenator(), batched=True)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}